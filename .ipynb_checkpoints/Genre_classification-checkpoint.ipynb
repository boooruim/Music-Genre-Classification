{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd5e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import glob\n",
    "import random, shutil\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if device != \"cuda\":\n",
    "        print(\"WARNING: For this notebook to perform best, \"\n",
    "            \"if possible, in the menu under `Runtime` -> \"\n",
    "            \"`Change runtime type.`  select `GPU` \")\n",
    "    else:\n",
    "        print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries.\n",
    "\n",
    "\n",
    "genre_name = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
    "\n",
    "\n",
    "# 'Data/Total' 폴더 생성\n",
    "\n",
    "if not os.path.exists('Data'):\n",
    "        os.mkdir('Data')\n",
    "\n",
    "# 'Data/Total' 폴더 생성\n",
    "parent_directory = 'Data/all'\n",
    "\n",
    "if not os.path.exists(parent_directory):\n",
    "        os.mkdir(parent_directory)\n",
    "\n",
    "\n",
    "# 'Data/Total'폴더에서 10개의 하위 폴더 생성\n",
    "for i in range(10):\n",
    "    folder_name = genre_name[i]\n",
    "    folder_path = os.path.join(parent_directory, folder_name)\n",
    "    \n",
    "    # 폴더가 이미 존재하지 않는 경우에만 생성\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "\n",
    "# 장르별 3second mel-spectrogram 생성\n",
    "\n",
    "original_data_dir = './archive/genres_original/'\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "\n",
    "    for j in range(100):\n",
    "\n",
    "        original_data = original_data_dir+genre_name[i]+f\"/{genre_name[i]}.{j:05d}.wav\"\n",
    "\n",
    "        if not os.path.exists(original_data):\n",
    "            continue\n",
    "\n",
    "        y, sr = librosa.load(original_data)\n",
    "        \n",
    "        segment_length = 3 * sr  # 3초 분량의 샘플 수\n",
    "        for k in range(0, 10):\n",
    "            plt.figure(figsize=(2**4, 2**4))\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            segment = y[k*segment_length:(k+1)*segment_length]\n",
    "            mel_3second = librosa.feature.melspectrogram(y = segment, sr=sr)\n",
    "            mel_3second_db = librosa.amplitude_to_db(mel_3second, ref=np.max)\n",
    "            \n",
    "            librosa.display.specshow(mel_3second_db, sr=sr)\n",
    "\n",
    "            plt.savefig(f'{parent_directory}/{genre_name[i]}/{j:05d}-{k}.png',dpi=2**3) #bbox_inches='tight', pad_inches = 0\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7db03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder with training, testing and validation data.\n",
    "\n",
    "spectrograms_dir = parent_directory\n",
    "folder_names = ['Data/train/', 'Data/test/', 'Data/val/']\n",
    "train_dir = folder_names[0]\n",
    "test_dir = folder_names[1]\n",
    "val_dir = folder_names[2]\n",
    "\n",
    "for f in folder_names:\n",
    "    if os.path.exists(f):\n",
    "        shutil.rmtree(f)\n",
    "        os.mkdir(f)\n",
    "    else:\n",
    "        os.mkdir(f)\n",
    "\n",
    "# Loop over all genres.\n",
    "\n",
    "genres = list(os.listdir(spectrograms_dir))\n",
    "for g in genres:\n",
    "    # find all images & split in train, test, and validation\n",
    "    src_file_paths= []\n",
    "    for im in glob.glob(os.path.join(spectrograms_dir, f'{g}',\"*.png\"), recursive=True):\n",
    "        src_file_paths.append(im)\n",
    "    random.shuffle(src_file_paths)\n",
    "    test_files = src_file_paths[0:100]\n",
    "    val_files = src_file_paths[100:200]\n",
    "    train_files = src_file_paths[200:]\n",
    "\n",
    "    #  make destination folders for train and test images\n",
    "    for f in folder_names:\n",
    "        if not os.path.exists(os.path.join(f + f\"{g}\")):\n",
    "            os.mkdir(os.path.join(f + f\"{g}\"))\n",
    "\n",
    "    # copy training and testing images over\n",
    "    for f in train_files:\n",
    "        shutil.copy(f, os.path.join(os.path.join(train_dir + f\"{g}\") + '/',os.path.split(f)[1]))\n",
    "    for f in test_files:\n",
    "        shutil.copy(f, os.path.join(os.path.join(test_dir + f\"{g}\") + '/',os.path.split(f)[1]))\n",
    "    for f in val_files:\n",
    "        shutil.copy(f, os.path.join(os.path.join(val_dir + f\"{g}\") + '/',os.path.split(f)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d430b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a CNN & train it to predict genres.\n",
    "class Conv_2d(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, ksize=7, dropout=0.1):\n",
    "        super(Conv_2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, ksize, padding = 1)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_channels=8, \n",
    "                       num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # convolutional layers\n",
    "        self.layer1 = Conv_2d(3, num_channels)\n",
    "        self.layer2 = Conv_2d(num_channels, num_channels*2)\n",
    "        self.layer3 = Conv_2d(num_channels*2, num_channels * 4)\n",
    "        self.layer4 = Conv_2d(num_channels * 4, num_channels * 8)\n",
    "        self.layer5 = Conv_2d(num_channels * 8, num_channels * 16,ksize=5)\n",
    "\n",
    "        # dense layers\n",
    "        self.dense1 = nn.Linear(num_channels * 16, 256)\n",
    "        self.dense_bn = nn.BatchNorm1d(256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # convolutional layers\n",
    "        out = self.layer1(x)\n",
    "        \n",
    "        out = self.layer2(out)\n",
    "\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.layer5(out)\n",
    "        \n",
    "        out = out.squeeze()\n",
    "\n",
    "        # dense layers\n",
    "        out = self.dense1(out)\n",
    "        out = self.dense_bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.dense2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a452adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model, device, train_loader, validation_loader, epochs):\n",
    "    criterion =  nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "    train_loss, validation_loss = [], []\n",
    "    train_acc, validation_acc = [], []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    with tqdm(range(epochs), unit='epoch') as tepochs:\n",
    "        tepochs.set_description('Training')\n",
    "        for epoch in tepochs:\n",
    "            model.train()\n",
    "            # keep track of the running loss\n",
    "            running_loss = 0.\n",
    "            correct, total = 0, 0\n",
    "\n",
    "            for data, target in train_loader:\n",
    "                # getting the training set\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                # Get the model output (call the model with the data from this batch)\n",
    "                output = model(data)\n",
    "                # Zero the gradients out)\n",
    "                optimizer.zero_grad()\n",
    "                # Get the Loss\n",
    "                loss  = criterion(output, target)\n",
    "                # Calculate the gradients\n",
    "                loss.backward()\n",
    "                # Update the weights (using the training step of the optimizer)\n",
    "                optimizer.step()\n",
    "\n",
    "                tepochs.set_postfix(loss=loss.item())\n",
    "                running_loss += loss  # add the loss for this batch\n",
    "\n",
    "                # get accuracy\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "            # append the loss for this epoch\n",
    "            train_loss.append(running_loss.detach().cpu().item()/len(train_loader))\n",
    "            train_acc.append(correct/total)\n",
    "\n",
    "            # evaluate on validation data\n",
    "            model.eval()\n",
    "            running_loss = 0.\n",
    "            correct, total = 0, 0\n",
    "\n",
    "            for data, target in validation_loader:\n",
    "                # getting the validation set\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                tepochs.set_postfix(loss=loss.item())\n",
    "                running_loss += loss.item()\n",
    "                # get accuracy\n",
    "                _, predicted = torch.max(output, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "\n",
    "            validation_loss.append(running_loss/len(validation_loader))\n",
    "            validation_acc.append(correct/total)\n",
    "\n",
    "            if running_loss < best_val_loss:\n",
    "                best_val_loss = running_loss\n",
    "                torch.save(model.state_dict(), 'weight.pth')\n",
    "\n",
    "    return train_loss, train_acc, validation_loss, validation_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7045f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc):\n",
    "    epochs = len(train_loss)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    ax1.plot(list(range(epochs)), train_loss, label='Training Loss')\n",
    "    ax1.plot(list(range(epochs)), validation_loss, label='Validation Loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Epoch vs Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(list(range(epochs)), train_acc, label='Training Accuracy')\n",
    "    ax2.plot(list(range(epochs)), validation_acc, label='Validation Accuracy')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title('Epoch vs Accuracy')\n",
    "    ax2.legend()\n",
    "    fig.set_size_inches(15.5, 5.5)\n",
    "    plt.show()\n",
    "    #plt.savefig(save_plot_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb63f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(device,model,test_loader):\n",
    "    GTZAN_GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "\n",
    "    load_state_dict(torch.load('weight.pth'))\n",
    "    print('loaded!')\n",
    "\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # reshape and aggregate chunk-level predictions\n",
    "            output = model(data)\n",
    "            _, pred = torch.max(output, 1)\n",
    "\n",
    "            # append labels and predictions\n",
    "            y_true.extend(target.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "\n",
    "    sns.set(font_scale=1.2)  # 폰트 크기 조정\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, xticklabels=GTZAN_GENRES, yticklabels=GTZAN_GENRES, cmap='YlGnBu')\n",
    "    plt.show()\n",
    "    print('Accuracy: %.4f' % accuracy)\n",
    "    #plt.savefig(save_plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading.\n",
    "\n",
    "folder_names = ['Data/train/', 'Data/test/', 'Data/val/']\n",
    "train_dir = folder_names[0]\n",
    "test_dir = folder_names[1]\n",
    "val_dir = folder_names[2]\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    val_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    val_dir,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e276db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_device()\n",
    "\n",
    "cnn = CNN().to(device)\n",
    "train_loss, train_acc, validation_loss, validation_acc = train(cnn, device, train_loader, val_loader, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1250a31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(train_loss, train_acc, validation_loss, validation_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b478924",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(device, cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8beb1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
